---
date: 2025-09-28
title: LLM 相关技术
---
## LLM
简单地理解，就是一个根据输入预测输出的函数。

## Function Calling
大模型（LLMs）不擅长逻辑处理，本质上是因为它们是**概率机器**，而不是**符号推理机器**。它们的核心能力是**模式匹配**和**预测**，而不是遵循严格的逻辑规则进行演绎。

但是类似于计算表达式等**逻辑处理过程**可以很好地使用代码**封装成一个函数**，有了现成的函数之后，大模型只需要提供对应的入参即可解决复杂地逻辑处理问题。

通过这种方式将大模型不擅长的逻辑处理问题转化为其最擅长的文本生成问题，能够高效地弥补大模型低逻辑处理能力。

eg：

![](https://raw.githubusercontent.com/lyydsheep/pic/main/20250928201650.png)

## MCP
为什么要有 MCP？

为了解决集成碎片化问题（标准化），这是 MCP 出现最直接的原因。在 MCP 之前，如果想要让一个 LLM 调用工具，由于各个大模型厂商提供的接口/规格不同，那么就必须为每一个平台（ChatGPT、Gemini）定制化功能相同的工具。这会带来极大的时间成本。

**没有什么问题是加一层抽象层解决不了的。**MCP的做法恰好印证了这一点，MCP 通过引入 MCP 客户端，作为 LLM 和外界沟通的代理。将原先工具接入 LLM 的问题，转化为将工具接入 MCP 客户端，屏蔽了不同 LLM 厂商之间的差异性。

![](https://raw.githubusercontent.com/lyydsheep/pic/main/20250928201612.png)

## A2A
A2A 协议是基于 Web 标准（HTTP、JSON-RPC、SSE）构建的，核心目的是打造 Agent 和 Agent 之间沟通的桥梁。

一个完整的 Agent 解决方案可能会使用到 MCP 和 A2A 两种协议。比如一个 Agent 通过 MCP访问数据获取最新的数据，然后通过 A2A 协议将

